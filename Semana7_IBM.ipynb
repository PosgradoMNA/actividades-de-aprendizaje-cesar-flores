{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuNUqcl+18kc+da7ayZUey",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PosgradoMNA/actividades-de-aprendizaje-cesar-flores/blob/main/Semana7_IBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#César Flores Vivanc\n",
        "#A01173318"
      ],
      "metadata": {
        "id": "Fc7FtmNkQ_Hp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Linear and multiple linear regression\n",
        "\n",
        "1. La regresión lineal refiere a una variable indpendiente para hacer una predicción\n",
        "\n",
        "2. La regresión multiple se refiere a las multiples variables independientes para hacer una predicción\n",
        "\n",
        "Simple linear regression\n",
        "\n",
        "1. El predictos (indepenediente) variable x\n",
        "2. El objetivo (dependiente) variable y\n",
        "\n",
        "    y= b0 + b1x\n",
        "\n",
        "b0 = el interceptor\n",
        "\n",
        "b1 = la pendiente\n",
        "\n",
        "Para usar la regresión lineal \n",
        "\n",
        "usar la libreria de Sklearn\n",
        "\n",
        "1. Importar lineal_model from scitik-learn\n",
        "\n",
        "\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "\n",
        "2. Crear a linear regresion objeto usando el constructor\n",
        "\n",
        "\n",
        "    lm=LinearRegression()\n",
        "\n",
        "3. definir las variables predecibles y variables objetivos\n",
        "\n",
        "\n",
        "    x = df[ ['highway-mpg']]\n",
        "    y = df['price']\n",
        "\n",
        "4. usar lm.fit(x.y) para el modelo, con los parametros b0 y b1\n",
        "\n",
        "\n",
        "    lm.fit(x,y)\n",
        "\n",
        "5. para obtener una predicción\n",
        "\n",
        "    Yhat = lm.predict(x)\n",
        "\n",
        "Tambien podemos ver los valores de la intercepción (b0) \n",
        "\n",
        "\n",
        "    lm.intercept_\n",
        "\n",
        "Y el valor de la pendiente\n",
        "\n",
        "    lm.coef_\n",
        "\n",
        "\n",
        "#Multiple linear regression (MLR)\n",
        "\n",
        "Este metódo se utiliza para explicar las relaciones entre \n",
        "\n",
        "1. un objetivo variable continuo (Y)\n",
        "2. un o mas predictores (X)\n",
        "\n",
        "\n",
        "    y=b0 +b1x1 + b2x2 +b3x3...\n",
        "\n",
        "b0 = interceptor\n",
        "\n",
        "b1 = coeficiente o parametro de x1\n",
        "\n",
        "Para realizar el predictor de 4 variables y almacenarlas en la variable z\n",
        "\n",
        "\n",
        "    z =df[ ['variable1','variable2','variable3','variable4']]\n",
        "\n",
        "entrenar el modelo\n",
        "\n",
        "    lm.fit(z, df['price'])\n",
        "\n",
        "Tambien podemos obtener un preditor de las variables dependientes\n",
        "\n",
        "    Yhat= lm.predict(x)\n",
        "\n",
        "para encontrar los valores de b0\n",
        "\n",
        "    lm.intercept_\n",
        "\n",
        "para encontrar el valor del coeficiente\n",
        "\n",
        "    lm.coef_\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fcKBBZnMRILw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelo de visualización\n",
        "\n",
        "Regresion plot\n",
        "\n",
        "da una buena estimacion de:\n",
        "\n",
        "1. la relacion entre dos variables\n",
        "2. la fortaleza de correlacion\n",
        "3. la dirección entre la relacion (positiva y negativa)\n",
        "\n",
        "\n",
        "Regression plot muestra una combinación de:\n",
        "1. escatterplot: donde cada punto representa una diferencia Y\n",
        "2. el ajuste de regresión lineal (y)\n",
        "\n",
        "\n",
        "    import seaborn as sns\n",
        "\n",
        "    sns.regplot(x = 'highway-mpg', y='price', data=df)\n",
        "    plt.ylim(0,)\n",
        "\n",
        "\n",
        "#Residual plot\n",
        "\n",
        "representa el error entre los valores actuales\n",
        "\n",
        "Se espera ver resultados tengan cero de media en el cual esten de forma lineal. En caso de no estar formados de forma lineal como corvatura o en forma de cono quiere decir que no representa una regresion lineal.\n",
        "\n",
        "para agreagar los errores se usa la libreria Seaborn\n",
        "\n",
        "\n",
        "    import seaborn as sns\n",
        "\n",
        "    sns.residplot(df['highway-mpg'], df['price']\n",
        "\n",
        "la primera variable de .residplot( serie de variables dependientes, serie de variables o objetivo)\n",
        "\n",
        "#Distibution plots\n",
        "\n",
        "Comparar las graficas de distribución\n",
        "\n",
        "1. adecuar los valores con los resultados del modelo\n",
        "2. los valores actuales\n",
        "\n",
        "\n",
        "    import seaborn as sns\n",
        "\n",
        "    axl = sns.distplot(df['price'], hist=False, color=\"r\", label=\"Actual value\")\n",
        "\n",
        "    sns.distplot(Yhat, hist=False, color=\"b\", label=\"Fitted Values\", ax = axl)\n",
        "    \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VuAwJ8Gnrtql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Polynomianl Regression and Pipelines\n",
        "\n",
        "1. Un especial caso general del modelo regresion lineal\n",
        "2. útil para descubrir una relación curvilenear\n",
        "\n",
        "se usa para poinomios cuadráticos y cúbicos\n",
        "\n",
        "Para usar polinomios se usará la libreria de scikit-learn\n",
        "\n",
        "\n",
        "    from skilearn.prepocesssing import PolynomialFeatures\n",
        "\n",
        "    pr = PolynomialFeatures(degree==2, include_bias=false)\n",
        "\n",
        "    x_polly= pr.fit_transform(x[['horsepower'.'curb-weight])\n",
        "\n",
        "#pre-processing\n",
        "\n",
        "Se puede Normalizar cada variable simultaneamente\n",
        "\n",
        "    from sklearn import StandardScaler\n",
        "\n",
        "    SCALE = StandardScaler()\n",
        "\n",
        "    SCALE.fit(x_data[['horsepower'.'curb-weight]])\n",
        "\n",
        "    x_scale = SCALE.transform(x_data[['horsepower'.'curb-weight]])\n",
        "\n",
        "\n",
        "#Pipelines\n",
        "\n",
        "1. Normalizacion\n",
        "2. Transformación Polynomial\n",
        "3. Linear Regression\n",
        "\n",
        "los puntos 1 y 2 son de transformacion y el tercero de regresion lineal\n",
        "\n",
        "    from sklearn.preprocessing import PolynomialFeatures\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.pipeline import Pipeline\n",
        "\n",
        "Instrucciones\n",
        "\n",
        "    input = [ ('scale',StandardScaler()),'poynomial',PolynomialFeatures(degree==2),('model',LinearRegression())]\n",
        "\n",
        "En el primer tuple('scale','polynomial','model') contiene el nombre del estimador, el segundo el modelo constructor\n",
        "\n",
        "    pipe = pipeline(input)\n",
        "\n",
        "\n",
        "    pipe.train(x['variable1','variable2','variable3'],y)\n",
        "\n",
        "    yhat = pipe.predict(x[['variable1','variable2','variable3']])\n"
      ],
      "metadata": {
        "id": "3n2eE6hD1Yga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Measure for in-Sample Evaluation\n",
        "\n",
        "1. Mean Squared Error (MSE)\n",
        "\n",
        "Evalua la diferencia entre la linea predictora con el resultado real entre la suma de todas las variables\n",
        "\n",
        "    from sklearn.metrics import\n",
        "\n",
        "    mean_squared_error(df['price'],Y_predict_simple_fit)\n",
        "\n",
        "2. R-squared (R^2)\n",
        "\n",
        "evalua la proximidad de una regresion lineal\n",
        "\n",
        "    x = df[['highway-mpg']]\n",
        "    y = df['price']\n",
        "\n",
        "    lm.fit(x, y)\n",
        "\n",
        "    lm.score(x, y)"
      ],
      "metadata": {
        "id": "CCqU-95SBFFL"
      }
    }
  ]
}